{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2530d817-6ae5-4887-9bfe-7d57f1d769eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from netCDF4 import Dataset as netCDFDataset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "import pandas as pd\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea21ed7c-543d-42ab-b4d1-ee6b960efe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_datetime = datetime.now()\n",
    "run = current_datetime.strftime(\"%Y-%m-%d %H:%M\")\n",
    "writer = SummaryWriter(f\"../runs/validation/rf/{run}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "36503834-4ba1-4ce6-a01d-f8a2ea3fede6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: (3616, 5, 45, 100)\n",
      "val_data: (402, 5, 45, 100)\n",
      "train_time(3616,)\n",
      "train_data_flat: (3616, 22500)\n",
      "val_data_flat: (402, 22500)\n"
     ]
    }
   ],
   "source": [
    "labels = netCDFDataset(\"../data/labels/GTD_1979-2019_JJAextd_8.nc\", mode=\"r\").variables[\n",
    "    \"blocking\"\n",
    "][:]\n",
    "data = netCDFDataset(\n",
    "    \"../data/geopotential_height_500hPa_era5_6hourly_z0001_daymean_2019_beginAdjust_1x1_final.nc\",\n",
    "    mode=\"r\",\n",
    ").variables[\"z_0001\"][:]\n",
    "xr_data = xr.open_dataset(xr.backends.NetCDF4DataStore(netCDFDataset(\n",
    "    \"../data/geopotential_height_500hPa_era5_6hourly_z0001_daymean_2019_beginAdjust_1x1_final.nc\",\n",
    "    mode=\"r\",\n",
    ")), decode_times=True)\n",
    "\n",
    "time = xr_data.time\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_data, val_data, train_labels, val_labels, train_time, val_time = train_test_split(\n",
    "    data, labels, time, test_size=0.1\n",
    ")\n",
    "\n",
    "# Reshape the input data to be flattened\n",
    "train_data_flat = train_data.reshape(\n",
    "    len(train_data), int(train_data.size / len(train_data))\n",
    ")\n",
    "val_data_flat = val_data.reshape(len(val_data), int(val_data.size / len(val_data)))\n",
    "\n",
    "print(\"train_data: \" + str(train_data.shape))\n",
    "print(\"val_data: \" + str(val_data.shape))\n",
    "print(\"train_time\" + str(train_time.shape))\n",
    "\n",
    "print(\"train_data_flat: \" + str(train_data_flat.shape))\n",
    "print(\"val_data_flat: \" + str(val_data_flat.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ee942127-c044-40f0-b768-c7cc16ab9d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: (8908, 5, 45, 100)\n",
      "val_data: (990, 5, 45, 100)\n",
      "train_data_flat: (8908, 22500)\n",
      "val_data_flat: (990, 22500)\n"
     ]
    }
   ],
   "source": [
    "ukesm_labels = netCDFDataset(\"../data/labels/GTD_UKESM1-0-LL_piControl_1960-2060_JJAextd.nc\", mode=\"r\").variables[\n",
    "    \"blocking\"\n",
    "][:]\n",
    "ukesm_data = netCDFDataset(\n",
    "    \"../data/500zg_day_UKESM1-0-LL_piControl_r1i1p1f2_gn_19600101-20601230_NHML_JJAextd_1x1_final.nc\",\n",
    "    mode=\"r\",\n",
    ").variables[\"z_0001\"][:]\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "ukesm_train_data, ukesm_val_data, ukesm_train_labels, ukesm_val_labels = train_test_split(\n",
    "    ukesm_data, ukesm_labels, test_size=0.1\n",
    ")\n",
    "\n",
    "# Reshape the input data to be flattened\n",
    "ukesm_train_data_flat = ukesm_train_data.reshape(\n",
    "    len(ukesm_train_data), int(ukesm_train_data.size / len(ukesm_train_data))\n",
    ")\n",
    "ukesm_val_data_flat = ukesm_val_data.reshape(len(ukesm_val_data), int(ukesm_val_data.size / len(ukesm_val_data)))\n",
    "\n",
    "print(\"train_data: \" + str(ukesm_train_data.shape))\n",
    "print(\"val_data: \" + str(ukesm_val_data.shape))\n",
    "\n",
    "print(\"train_data_flat: \" + str(ukesm_train_data_flat.shape))\n",
    "print(\"val_data_flat: \" + str(ukesm_val_data_flat.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c4ba6d81-c56b-4a22-9d4f-1b898218470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(verbose=1)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [None],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"bootstrap\": [True],\n",
    "    \"max_features\": [\"log2\"],\n",
    "}\n",
    "\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_classifier, param_grid=param_grid, cv=5, scoring=[\"f1\", \"precision\", \"recall\"], refit=\"f1\", n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "77000721-89b1-4810-95a1-070a733163d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model (era5)\n",
      "training finished\n"
     ]
    }
   ],
   "source": [
    "print(\"training model (era5)\")\n",
    "grid_search.fit(train_data_flat, train_labels)\n",
    "print(\"training finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3e0114f8-8251-4222-b492-16cd02b66f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "era5 score: 0.7901234567901235\n",
      "ukesm score: 0.7304347826086957\n"
     ]
    }
   ],
   "source": [
    "ukesm_val_predictions = grid_search.predict(ukesm_val_data_flat)\n",
    "val_predictions = grid_search.predict(val_data_flat)\n",
    "print(\"era5 score: \" + str(f1_score(val_labels, val_predictions)))\n",
    "print(\"ukesm score: \" + str(f1_score(ukesm_val_labels, ukesm_val_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab0cc757-d24b-4398-9dc0-d96677f76f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access grid search results\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Save results to a CSV file\n",
    "results_df.to_csv('grid_search_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "61894f0c-8578-43af-977b-bb12bbf53960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false_positives: 15\n",
      "false_negatives: 36\n",
      "begin val: <xarray.DataArray 'time' ()>\n",
      "array('2003-08-16T09:00:00.000000000', dtype='datetime64[ns]')\n",
      "Coordinates:\n",
      "    time     datetime64[ns] 2003-08-16T09:00:00\n",
      "Attributes:\n",
      "    standard_name:  time\n",
      "    long_name:      time\n",
      "    bounds:         time_bnds\n",
      "    axis:           T\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "false_positives = (val_predictions == 1) & (val_labels == 0)\n",
    "false_negatives = (val_predictions == 0) & (val_labels == 1)\n",
    "\n",
    "count_false_positives = torch.sum(torch.tensor(false_positives)).item()\n",
    "count_false_negatives = torch.sum(torch.tensor(false_negatives)).item()\n",
    "\n",
    "\n",
    "print(\"false_positives: \" + str(count_false_positives))\n",
    "print(\"false_negatives: \" + str(count_false_negatives))\n",
    "\n",
    "print(\"begin val: \" + str(val_time[0]))\n",
    "\n",
    "for idx, (fp, fn) in enumerate(zip(false_positives, false_negatives)):\n",
    "    if fp.item():\n",
    "        writer.add_image(\n",
    "            f\"false-positive/rf_{np.datetime_as_string(val_time.data[idx], unit='s')}\", torch.tensor(val_data[idx]).view((1, 225, -1))\n",
    "        )\n",
    "    if fn.item():\n",
    "        writer.add_image(\n",
    "            f\"false-negative/rf_{np.datetime_as_string(val_time.data[idx], unit='s')}\", torch.tensor(val_data[idx]).view((1, 225, -1))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24d2976-dd02-4936-8eb1-115e244fd5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blocking",
   "language": "python",
   "name": "blocking"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
